{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "IcFR1bw1Frsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "AsXzKnd0Xioq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foundations = ['care','harm','fairness','cheating','loyalty','betrayal','authority','subversion','sanctity','degradation']"
      ],
      "metadata": {
        "id": "-oa_4WurXL0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the datasets to be used as locals files "
      ],
      "metadata": {
        "id": "nm_D9vRmGSmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"USC-MOLA-Lab/MFRC\")\n",
        "df_annotated = pd.DataFrame(dataset[\"train\"])\n",
        "idx = []\n",
        "#found = []\n",
        "\n",
        "for i in range(len(df_annotated)):\n",
        "\n",
        "  foundation = df_annotated[\"annotation\"].iloc[i]\n",
        "  if foundation.lower() in foundations:\n",
        "    pass \n",
        "  else:\n",
        "    idx.append(i)\n",
        "idx_ = df_annotated.iloc[idx].index.values    \n",
        "df_anno = df_annotated.drop(index = idx_)\n",
        "df_annotated[\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "jjpW4qFWXM4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1N0U-i4PxT_DmTru0r7T5po-9f9cwGgB8 -O RedditComments2.csv\n",
        "!gdown --id 1dlV7huXQfim8brL7LIBy-M2kFR63P2Oh -O Reddit_metadata2.csv\n",
        "!gdown --id 1vT1g4Crj6s6z2YNjSyPx5Fvz5KTpBYSB -O annottated_reddit.csv"
      ],
      "metadata": {
        "id": "P_wKUDbxGSKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_numbers(text):\n",
        "  result = re.sub(r'\\d+', '', text)\n",
        "  return result"
      ],
      "metadata": {
        "id": "B4LjusJOPtiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments= pd.read_csv(\"RedditComments2.csv\")\n",
        "df_meta = pd.read_csv(\"Reddit_metadata2.csv\")\n",
        "df_comments.drop_duplicates(inplace= True)\n",
        "df_comments.dropna(inplace=True)\n",
        "df_meta.drop_duplicates(inplace= True)\n",
        "df_meta.dropna(inplace=True)\n",
        "df_comments.head()\n",
        "df_annotated = pd.read_csv(\"annottated_reddit.csv\")\n",
        "df_annotated.drop_duplicates(inplace= True)\n",
        "df_annotated.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "HNoUvHRmFsv0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mg5IlhZKO-u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments.head()"
      ],
      "metadata": {
        "id": "QlkBMewiFsyq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c8841b44-e5e1-42eb-f5c4-c5cd4e12577b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 comment_id comment_parent_id  \\\n",
              "0           0    gk54wx6         t3_l2d2ba   \n",
              "1           1    gk4u2ho         t3_l2d2ba   \n",
              "2           2    gk5281a         t3_l2d2ba   \n",
              "3           3    gk4nwfl         t3_l2d2ba   \n",
              "4           4    gk4ovgd         t3_l2d2ba   \n",
              "\n",
              "                                        comment_body comment_link_id  \\\n",
              "0  I have an adult brother with Down Syndrome who...       t3_l2d2ba   \n",
              "1  >am I just overthinking the entire situation?\\...       t3_l2d2ba   \n",
              "2  I mentored an adult with Down Syndrome.  He sp...       t3_l2d2ba   \n",
              "3  No harm in checking, he could have been practi...       t3_l2d2ba   \n",
              "4  Be a good'un and go ask him, it's only fair be...       t3_l2d2ba   \n",
              "\n",
              "                             comment_important_words  \n",
              "0  ['adult', 'brother', 'syndrom', 'live', 'indep...  \n",
              "1  ['overthink', 'entir', 'situat', 'think', '99'...  \n",
              "2  ['mentor', 'adult', 'syndrom', 'spoke', 'well'...  \n",
              "3  ['harm', 'check', 'could', 'practic', 'crane',...  \n",
              "4  ['good', 'un', 'go', 'ask', 'fair', 'may', 'ac...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-629ec3d2-ea3a-4801-8ffd-9983ccbc1e3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>comment_parent_id</th>\n",
              "      <th>comment_body</th>\n",
              "      <th>comment_link_id</th>\n",
              "      <th>comment_important_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>gk54wx6</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>I have an adult brother with Down Syndrome who...</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>['adult', 'brother', 'syndrom', 'live', 'indep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>gk4u2ho</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>&gt;am I just overthinking the entire situation?\\...</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>['overthink', 'entir', 'situat', 'think', '99'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>gk5281a</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>I mentored an adult with Down Syndrome.  He sp...</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>['mentor', 'adult', 'syndrom', 'spoke', 'well'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>gk4nwfl</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>No harm in checking, he could have been practi...</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>['harm', 'check', 'could', 'practic', 'crane',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>gk4ovgd</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>Be a good'un and go ask him, it's only fair be...</td>\n",
              "      <td>t3_l2d2ba</td>\n",
              "      <td>['good', 'un', 'go', 'ask', 'fair', 'may', 'ac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629ec3d2-ea3a-4801-8ffd-9983ccbc1e3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-629ec3d2-ea3a-4801-8ffd-9983ccbc1e3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-629ec3d2-ea3a-4801-8ffd-9983ccbc1e3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments[\"comment_body\"] = np.array([t.lower() for t in df_comments[\"comment_body\"]])"
      ],
      "metadata": {
        "id": "1-b3wWT0Fs1N"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated.head()"
      ],
      "metadata": {
        "id": "kAhQRkkoFs3l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "681e48b8-df6c-4957-9733-cbbf4d171572"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text   subreddit  \\\n",
              "0  MLP doesn't need to wait for a referendum to b...      europe   \n",
              "1  Or - or - assclowns like Le Pen and Farage cou...   worldnews   \n",
              "2  Congratulations on your victory Macron voters....   worldnews   \n",
              "3  The German Constitution did not let Hitler bec...  neoliberal   \n",
              "4  So Republicans really are for liberal policies...    politics   \n",
              "\n",
              "            bucket    annotator annotation          confidence  \n",
              "0  French politics  annotator00  Authority       Not Confident  \n",
              "1  French politics  annotator02   Equality           Confident  \n",
              "2  French politics  annotator00       Care       Not Confident  \n",
              "3  French politics  annotator02   Equality  Somewhat Confident  \n",
              "4      US Politics  annotator03   Equality           Confident  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37d3c4ba-114f-4339-824e-e9f080e55779\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>bucket</th>\n",
              "      <th>annotator</th>\n",
              "      <th>annotation</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLP doesn't need to wait for a referendum to b...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>annotator00</td>\n",
              "      <td>Authority</td>\n",
              "      <td>Not Confident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Or - or - assclowns like Le Pen and Farage cou...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>French politics</td>\n",
              "      <td>annotator02</td>\n",
              "      <td>Equality</td>\n",
              "      <td>Confident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Congratulations on your victory Macron voters....</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>French politics</td>\n",
              "      <td>annotator00</td>\n",
              "      <td>Care</td>\n",
              "      <td>Not Confident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The German Constitution did not let Hitler bec...</td>\n",
              "      <td>neoliberal</td>\n",
              "      <td>French politics</td>\n",
              "      <td>annotator02</td>\n",
              "      <td>Equality</td>\n",
              "      <td>Somewhat Confident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So Republicans really are for liberal policies...</td>\n",
              "      <td>politics</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>annotator03</td>\n",
              "      <td>Equality</td>\n",
              "      <td>Confident</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d3c4ba-114f-4339-824e-e9f080e55779')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37d3c4ba-114f-4339-824e-e9f080e55779 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37d3c4ba-114f-4339-824e-e9f080e55779');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from nltk.stem.porter import *\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "  \n",
        "\n",
        "def tweet_to_words(tweet):\n",
        "\n",
        "  ''' Convert tweet text into a sequence of words '''\n",
        "  \n",
        "  # convert to lowercase\n",
        "  text = tweet.lower()\n",
        "  # remove non letters\n",
        "  text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
        "  # tokenize\n",
        "  words = text.split()\n",
        "  # remove stopwords\n",
        "  words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "  # apply stemming\n",
        "  words = [PorterStemmer().stem(w) for w in words]\n",
        "  # return list\n",
        "  return words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mmmrzN8Qc1U",
        "outputId": "6f38bb02-e725-4267-e46d-806e619f1934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated[\"lemmatizing_words\"] = np.array([str(tweet_to_words(t)) for t in df_annotated[\"text\"]])"
      ],
      "metadata": {
        "id": "8GHaYydhOWfd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foundations = ['care','harm','fairness','cheating','loyalty','betrayal','authority','subversion', \"liberty\", \"opression\"]"
      ],
      "metadata": {
        "id": "pH40SA7wh6Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated[\"text\"][df_annotated[\"annotation\"] ==\"Proportionality\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiW91qmBhVtm",
        "outputId": "800cccac-2399-4c48-f798-aa230d7aae75"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7       What proportion of tipped workers don't want i...\n",
              "17      It's not useless and the free market has *not*...\n",
              "37      Bourdain was fighting with depression. I've be...\n",
              "45      The court ruled that no reasonable viewer woul...\n",
              "52      What surprises me even more is many of these f...\n",
              "                              ...                        \n",
              "4955    Wow some of them really are salty af. \\n\\n\"Mac...\n",
              "4965    Can you handle him at his Hollande? Because if...\n",
              "4973    Introducing partial proportional voting to the...\n",
              "4982    Not really, most sugar daddies are older marri...\n",
              "4992    Yeah that was my point. Maybe Hillary is more ...\n",
              "Name: text, Length: 472, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated[\"text\"].iloc[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lhyk3lA0hmEA",
        "outputId": "1f9697ba-2ebe-42a8-97c5-883ee1c54ad1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What proportion of tipped workers don't want it to change?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated[\"annotation\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psUM6FFlOWl5",
        "outputId": "68d89061-0e04-43f4-e9e8-e5940c1e80b9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Care                                  973\n",
              "Authority                             814\n",
              "Equality                              618\n",
              "Proportionality                       472\n",
              "Loyalty                               306\n",
              "                                     ... \n",
              "Purity,Authority,Equality               1\n",
              "Care,Equality,Purity                    1\n",
              "Care,Equality,Loyalty                   1\n",
              "Loyalty,Equality,Proportionality        1\n",
              "Proportionality,Equality,Authority      1\n",
              "Name: annotation, Length: 96, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "JinLrL1vVLk4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For type hinting\n",
        "from typing import List\n",
        "def w2v_trainer(doc_tokens =  List[str], epochs: int = 10,\n",
        "                workers: int = 3,\n",
        "                vector_size: int = 300,\n",
        "                window: int = 5,\n",
        "                min_count: int = 2):\n",
        "    \"\"\" \n",
        "    Going through a list of lists, where each list within the main list contains a set of tokens from a doc, this function trains a Word2Vec model,\n",
        "    then creates two objects to store keyed vectors and keyed vocabs   \n",
        "    Parameters:\n",
        "    doc_tokens   : A tokenized document \n",
        "    epochs       : Number of epochs training over the corpus\n",
        "    workers      : Number of processors (parallelization)\n",
        "    vector_size  : Dimensionality of word embeddings\n",
        "    window       : Context window for words during training\n",
        "    min_count    : Ignore words that appear less than this\n",
        "    Returns:\n",
        "    keyed_vectors       : A word2vec vocabulary model\n",
        "    keyed_vocab \n",
        "    \n",
        "    \"\"\"\n",
        "    w2v_model = Word2Vec(doc_tokens,\n",
        "                         epochs=10,\n",
        "                         workers=3,\n",
        "                         vector_size=300,\n",
        "                         window=5,\n",
        "                         min_count=2)\n",
        "    \n",
        "    # create objects to store keyed vectors and keyed vocabs\n",
        "    keyed_vectors = w2v_model.wv\n",
        "    keyed_vocab = keyed_vectors.key_to_index\n",
        "    \n",
        "    return keyed_vectors, keyed_vocab\n",
        "    "
      ],
      "metadata": {
        "id": "b8pY7xJYZfHk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vec, vocab_dict = w2v_trainer(df_comments[\"comment_important_words\"].values())\n",
        "print(word_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIwgrDCzZfKD",
        "outputId": "b5e7dd9c-4469-4f35-f41b-86b8b9865eb1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyedVectors<vector_size=300, 41 keys>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments[\"comment_important_words\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsfA8exAZfM6",
        "outputId": "779ccb91-91d8-4984-95e1-d22d333715b0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ['adult', 'brother', 'syndrom', 'live', 'indep...\n",
              "1       ['overthink', 'entir', 'situat', 'think', '99'...\n",
              "2       ['mentor', 'adult', 'syndrom', 'spoke', 'well'...\n",
              "3       ['harm', 'check', 'could', 'practic', 'crane',...\n",
              "4       ['good', 'un', 'go', 'ask', 'fair', 'may', 'ac...\n",
              "                              ...                        \n",
              "7083    ['bro', 'made', 'mistak', 'sorri', 'perfect', ...\n",
              "7084    ['ir', 'trip', 'think', 'report', 'gift', 'nam...\n",
              "7085                          ['common', 'misunderstand']\n",
              "7086    ['ye', 'also', 'sell', 'someon', 'market', 'wo...\n",
              "7087                          ['properti', 'tax', 'work']\n",
              "Name: comment_important_words, Length: 4699, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vec[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_IkJNNsZfPj",
        "outputId": "aa787baa-f8d4-4577-bd68-52f836df55d5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.64622724e-01,  7.33440788e-03,  1.63626410e-02,  1.82186157e-01,\n",
              "       -1.23987108e-01,  1.66091070e-01,  1.17222250e-01,  7.64761865e-03,\n",
              "        4.86143259e-03, -2.79219039e-02, -3.34663019e-02, -1.07294910e-01,\n",
              "       -6.36387989e-02, -1.03187762e-01,  6.89382330e-02,  5.89061491e-02,\n",
              "       -2.74437070e-01,  7.30732456e-02,  1.14516497e-01, -5.68372458e-02,\n",
              "        1.28345713e-01,  1.94325879e-01, -5.60992770e-02,  1.04937680e-01,\n",
              "        1.95379797e-02, -3.14322934e-02,  4.51897353e-01, -2.38913566e-01,\n",
              "       -1.97140217e-01,  5.65069765e-02, -1.86316416e-01,  3.12230103e-02,\n",
              "        1.95791587e-01,  7.58144036e-02, -1.90628052e-01,  6.53116126e-03,\n",
              "        2.90427476e-01,  1.74324811e-01, -4.37632427e-02,  2.53378332e-01,\n",
              "       -2.22319774e-02,  1.61749739e-02, -1.92347139e-01,  1.01258829e-01,\n",
              "       -2.13491648e-01,  5.18669784e-02,  7.94762895e-02,  1.73645467e-01,\n",
              "        1.31996810e-01, -3.74557562e-02,  1.34735554e-02,  1.86693877e-01,\n",
              "        4.03368287e-02, -2.67798334e-01,  1.86195716e-01, -2.27185562e-02,\n",
              "        1.21158928e-01, -1.02084972e-01,  6.51816800e-02, -8.27082619e-02,\n",
              "        8.54131207e-03,  2.69016653e-01, -1.82149291e-01, -2.47489154e-01,\n",
              "        6.62945807e-02, -3.64385486e-01,  1.00383312e-01, -2.76136603e-02,\n",
              "        1.98481649e-01, -2.60606427e-02, -3.55280973e-02, -3.59699190e-01,\n",
              "       -1.57930374e-01,  1.13398083e-01, -1.75172761e-01,  1.01705298e-01,\n",
              "        7.91526064e-02,  4.20462759e-03, -1.46440551e-01,  3.42005581e-01,\n",
              "        2.15553150e-01,  4.44330834e-02,  1.70178086e-01, -1.81444243e-01,\n",
              "       -1.30860014e-02,  1.87555358e-01, -9.58862007e-02,  1.88215166e-01,\n",
              "        9.90835950e-02,  3.34305689e-02,  9.50609371e-02,  1.20340534e-01,\n",
              "       -1.89985469e-01,  2.21651018e-01, -8.92340951e-03,  1.80598706e-01,\n",
              "       -2.69306391e-01, -1.03346407e-01, -5.38809821e-02,  4.23574038e-02,\n",
              "       -2.96592742e-01,  3.12746763e-02,  1.93197548e-01, -5.48922010e-02,\n",
              "        7.02108741e-02, -1.19048178e-01,  1.24444589e-01,  7.11663365e-02,\n",
              "       -5.63484151e-04, -1.89019516e-01,  2.68443644e-01, -2.08163843e-01,\n",
              "       -3.34306769e-02, -8.96907151e-02,  8.86671767e-02, -7.87424892e-02,\n",
              "        7.50130638e-02, -3.09068114e-02, -2.27323934e-01,  3.05028439e-01,\n",
              "        1.25943378e-01, -2.60335714e-01, -4.20003152e-03,  1.28298044e-01,\n",
              "        2.98827916e-01, -1.26684248e-01, -4.90886755e-02,  1.69993639e-01,\n",
              "       -2.26085275e-01,  1.08586989e-01,  1.95132956e-01, -3.53439860e-02,\n",
              "       -3.17142963e-01,  2.62274832e-01,  7.07235001e-03,  3.94928828e-02,\n",
              "        2.39522785e-01,  2.96552360e-01,  1.29885718e-01,  2.56568015e-01,\n",
              "       -1.52096033e-01, -2.35577762e-01, -5.09918407e-02, -8.51573423e-03,\n",
              "       -1.06833279e-01,  5.66050038e-02,  5.84258258e-01, -1.76975518e-01,\n",
              "       -3.91804203e-02,  2.75179118e-01,  1.48495048e-01, -1.08009465e-01,\n",
              "        1.57192200e-01, -3.66561189e-02, -4.35377389e-01, -1.67795599e-01,\n",
              "       -3.02409232e-02, -5.32095972e-03, -7.44464770e-02,  1.89825609e-01,\n",
              "        2.85563078e-02,  1.29827157e-01,  6.20946251e-02, -5.12558579e-01,\n",
              "       -9.47951376e-02,  4.87718440e-04,  4.87057090e-01, -1.71471894e-01,\n",
              "       -5.74555546e-02,  1.69645905e-01, -2.26189807e-01,  2.38472134e-01,\n",
              "       -2.57702470e-01, -4.43176739e-03, -2.30001155e-02,  2.17260346e-01,\n",
              "       -3.10597420e-01,  1.21636823e-01,  1.30904555e-01,  4.77986708e-02,\n",
              "        1.71628520e-01, -9.88555923e-02,  9.14536491e-02, -8.26337188e-02,\n",
              "       -1.44955292e-01,  1.23926856e-01, -1.96728125e-01, -4.65619594e-01,\n",
              "       -1.24277718e-01, -1.07759602e-01, -8.55523869e-02, -3.67258132e-01,\n",
              "        4.75424439e-01, -2.97607690e-01, -1.83272392e-01,  3.08815360e-01,\n",
              "        5.85321009e-01,  9.52464938e-02, -1.87164724e-01, -1.75152972e-01,\n",
              "        1.04459085e-01, -9.60420892e-02, -4.00844425e-01, -5.49520515e-02,\n",
              "       -4.72497374e-01,  5.82732148e-02, -6.17176712e-01, -2.75713772e-01,\n",
              "        2.80262470e-01,  3.09187084e-01,  6.07127063e-02,  6.16274655e-01,\n",
              "       -1.88687086e-01,  3.26442719e-01, -5.16095936e-01,  1.69948041e-01,\n",
              "        1.11100607e-01,  6.63642883e-01,  4.66162786e-02,  3.23034972e-01,\n",
              "       -9.71233025e-02, -6.30395710e-01,  2.89145231e-01,  4.59972799e-01,\n",
              "        4.73439656e-02,  4.84276302e-02, -6.76580239e-03,  1.80846021e-01,\n",
              "        8.40338841e-02,  2.74453610e-01, -2.65112132e-01,  1.17004544e-01,\n",
              "        3.96645546e-01,  9.34964269e-02,  7.84531236e-01, -6.40201330e-01,\n",
              "       -4.49342310e-01, -8.57590318e-01, -6.49250388e-01,  1.01674342e+00,\n",
              "       -5.23257017e-01,  7.03941405e-01, -9.26647931e-02, -2.92980462e-01,\n",
              "       -5.17099380e-01,  1.90897673e-01,  3.52127492e-01,  1.59943730e-01,\n",
              "        2.72394240e-01, -4.16742563e-01, -2.24587932e-01,  2.12734371e-01,\n",
              "       -3.20720464e-01,  5.14096439e-01,  3.49572897e-01,  7.25083590e-01,\n",
              "       -3.08793366e-01, -1.09072007e-01, -1.55433118e-01, -1.73382438e-03,\n",
              "        1.01950958e-01, -6.85224775e-03, -2.91309267e-01,  2.38876194e-01,\n",
              "        3.24941754e-01,  3.64727974e-02,  2.40335435e-01, -3.34553793e-02,\n",
              "        1.99024886e-01, -7.96014816e-02, -5.67041971e-02, -3.59119126e-03,\n",
              "       -2.67609097e-02, -2.69002505e-02, -1.19383886e-01,  3.07496309e-01,\n",
              "        2.49556124e-01, -4.71658520e-02,  2.56682485e-01, -2.75612120e-02,\n",
              "       -5.17697707e-02,  6.43547028e-02,  1.31886885e-01, -4.04959291e-01,\n",
              "        7.57113993e-02, -4.13819313e-01,  1.07769407e-01, -6.21348135e-02,\n",
              "        1.58947378e-01, -7.20213726e-02, -2.08358467e-01, -2.97427438e-02,\n",
              "       -2.45308012e-01, -3.03736329e-01, -3.01554918e-01, -2.07901392e-02,\n",
              "        1.94391623e-01,  7.93324485e-02, -2.00879686e-02,  3.62793297e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zeiWOlyZfSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, UpSampling2D,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "import tensorflow as tf\n",
        "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pickle, os, zipfile, glob\n",
        "\n",
        "    \n",
        "\n",
        "class PseudoCallback(Callback):\n",
        "\n",
        "  def __init__(self, model, n_labeled_sample, batch_size, X, Y, X_unlabeled, n_classes, padding_len = 1000):\n",
        "\n",
        "    #how many samples n labels to take at a time (streaming)\n",
        "    self.n_labeled_sample = n_labeled_sample\n",
        "    self.batch_size = batch_size\n",
        "    self.model = model\n",
        "    #how many classes in the data set\n",
        "    self.n_classes = n_classes\n",
        "    #this is to make sure evey vector has the same number of words\n",
        "    self.maxlen =padding_len\n",
        "\n",
        "    #given x and y (which are labeled), split the data into train and test\n",
        "    X_train, self.X_test, y_train, self.y_test = train_test_split(X,Y,test_size=0.3, random_state=100, shuffle=True)\n",
        "    \n",
        "    #shuffle the indices for random order, that way lables arent lost\n",
        "    indices = np.arange(X_train.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    self.X_train_labeled = tf.keras.utils.pad_sequences(X_train[indices[:n_labeled_sample]], self.maxlen)\n",
        "    self.y_train_labeled = y_train[indices[:n_labeled_sample]]\n",
        "\n",
        "    #this one has the unlabeled variables we input\n",
        "    self.X_train_unlabeled = tf.keras.utils.pad_sequences(X_unlabeled[indices[n_labeled_sample:]], self.maxlen)\n",
        "\n",
        "    #this is to test the performance on the labeled data\n",
        "    self.y_train = y_train[indices[n_labeled_sample:]]\n",
        "    self.X_test = tf.keras.utils.pad_sequences(X_train, self.maxlen)\n",
        "\n",
        "    #cant because now I will have many labels (10),if needed the values need tobe random vals similar to hot encoded labels\n",
        "    #self.y_train_unlabeled_prediction = np.random.randint(2, size=(self.y_train_unlabeled_groundtruth.shape[0]))\n",
        "    #self.y_train_unlabeled_prediction = np.random.choice(y_train, size=(self.y_train.shape[0]))\n",
        "   \n",
        "    self.train_steps_per_epoch = X_train.shape[0] // batch_size\n",
        "    self.test_stepes_per_epoch = self.X_test.shape[0] // batch_size\n",
        "    \n",
        "    self.alpha_t = 0.0\n",
        "\n",
        "    self.unlabeled_accuracy = []\n",
        "    self.labeled_accuracy = []\n",
        "\n",
        "  def train_mixture(self):\n",
        "    \n",
        "    X_train_join = np.r_[self.X_train_labeled, self.X_train_unlabeled]\n",
        "    y_train_join = np.r_[self.y_train_labeled, self.y_train_unlabeled_prediction]\n",
        "    flag_join = np.r_[np.repeat(0.0, self.X_train_labeled.shape[0]),\n",
        "                      np.repeat(1.0, self.X_train_unlabeled.shape[0])].reshape(-1,1)\n",
        "    indices = np.arange(flag_join.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    return X_train_join[indices], y_train_join[indices], flag_join[indices]\n",
        "\n",
        "  def train_generator(self):\n",
        "    while True:\n",
        "        X, y, flag = self.train_mixture()\n",
        "        n_batch = X.shape[0] // self.batch_size\n",
        "        for i in range(n_batch):\n",
        "            X_batch = (X[i*self.batch_size:(i+1)*self.batch_size]).astype(np.float32)\n",
        "            y_batch = to_categorical(y[i*self.batch_size:(i+1)*self.batch_size], self.n_classes)\n",
        "            y_batch = np.c_[y_batch, flag[i*self.batch_size:(i+1)*self.batch_size]]\n",
        "            yield X_batch, y_batch\n",
        "\n",
        "  def test_generator(self):\n",
        "      while True:\n",
        "          indices = np.arange(self.y_test.shape[0])\n",
        "          np.random.shuffle(indices)\n",
        "          for i in range(len(indices)//self.batch_size):\n",
        "              current_indices = indices[i*self.batch_size:(i+1)*self.batch_size]\n",
        "              X_batch = (self.X_test[current_indices]).astype((np.float32))\n",
        "              \n",
        "              #(np.object)\n",
        "              y_batch = to_categorical(self.y_test[current_indices], self.n_classes)\n",
        "              y_batch = np.c_[y_batch, np.repeat(0.0, y_batch.shape[0])] \n",
        "              yield X_batch, y_batch\n",
        "\n",
        "  def loss_function(self, y_true, y_pred):\n",
        "      y_true_item = y_true[:, :self.n_classes]\n",
        "      unlabeled_flag = y_true[:, self.n_classes]\n",
        "      entropies = categorical_crossentropy(y_true_item, y_pred)\n",
        "      coefs = 1.0-unlabeled_flag + self.alpha_t * unlabeled_flag # 1 if labeled, else alpha_t\n",
        "      return coefs * entropies\n",
        "\n",
        "  def accuracy(self, y_true, y_pred):\n",
        "      y_true_item = y_true[:, :self.n_classes]\n",
        "      return categorical_accuracy(y_true_item, y_pred)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "      #defining alpha\n",
        "      if epoch < 10:\n",
        "          self.alpha_t = 0.0\n",
        "      elif epoch >= 70:\n",
        "          self.alpha_t = 3.0\n",
        "      else:\n",
        "          self.alpha_t = (epoch - 10.0) / (70.0-10.0) * 3.0\n",
        "    \n",
        "      self.y_train_unlabeled_prediction = np.argmax(\n",
        "          self.model.predict(self.X_train_unlabeled), axis=-1,) \n",
        "      y_train_labeled_prediction = np.argmax(\n",
        "          self.model.predict(self.X_train_labeled), axis=-1)\n",
        "\n",
        "      self.unlabeled_accuracy.append(np.mean(\n",
        "          self.y_train_unlabeled_groundtruth == self.y_train_unlabeled_prediction))\n",
        "      self.labeled_accuracy.append(np.mean(\n",
        "          self.y_train_labeled == y_train_labeled_prediction))\n",
        "      print(f\"labeled accuracy {self.labeled_accuracy[-1]}, unlabeled accuracy : {self.unlabeled_accuracy[-1]}\")\n",
        "\n",
        "  def on_train_end(self, logs):\n",
        "      y_true = np.ravel(self.y_test)\n",
        "      emb_model = Model(self.model.input, self.model.layers[-2].output)\n",
        "      embedding = emb_model.predict(self.X_test )\n",
        "      proj = TSNE(n_components=2).fit_transform(embedding)\n",
        "      cmp = plt.get_cmap(\"tab10\")\n",
        "      plt.figure()\n",
        "      for i in range(10):\n",
        "          select_flag = y_true == i\n",
        "          plt_latent = proj[select_flag, :]\n",
        "          plt.scatter(plt_latent[:,0], plt_latent[:,1], color=cmp(i), marker=\".\")\n",
        "      plt.savefig(f\"result_pseudo_trans_mobile/embedding_{self.n_labeled_sample:05}.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "42OuXNWUCvgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foundations = ['care','harm','fairness','cheating','loyalty','betrayal','authority','subversion','sanctity','degradation']\n",
        "\n",
        "virtues = ['care','fairness','loyalty','authority','sanctity']\n",
        "vices = ['harm','cheating','betrayal','subversion','degradation']\n",
        "\n",
        "base_f = ['care_p','fairness_p','loyalty_p','authority_p','sanctity_p']\n",
        "sents = ['care_sent','fairness_sent','loyalty_sent','authority_sent','sanctity_sent']"
      ],
      "metadata": {
        "id": "nlq_Lgu0Ttx0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}