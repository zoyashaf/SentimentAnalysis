{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e14-fbFkvh47"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "import spacy  # For preprocessing\n",
        "import numpy as np\n",
        "from langdetect import detect\n",
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_language(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "    except:\n",
        "        lang = 'unknown'\n",
        "    return lang\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Party         Handle                                              Tweet\n",
              "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
              "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
              "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
              "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
              "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = '/Users/shafz/OneDrive/Documents/deep-learning-final-project-yelp_reviews_classification/data/raw'\n",
        "tweets = pd.read_csv(path+'/ExtractedTweets.csv')\n",
        "tweets.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94I4n1hxnqm",
        "outputId": "a311a695-0a19-49de-a55a-fad32427923d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Republican    44392\n",
              "Democrat      42068\n",
              "Name: Party, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets['Party'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RepDarrenSoto     200\n",
              "RepMarkMeadows    200\n",
              "RepDaveJoyce      200\n",
              "RodneyDavis       200\n",
              "RepLukeMesser     200\n",
              "                 ... \n",
              "HouseAdmnGOP      199\n",
              "RepEliotEngel     199\n",
              "Jim_Jordan        197\n",
              "RepVisclosky      197\n",
              "collinpeterson     80\n",
              "Name: Handle, Length: 433, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets['Handle'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EHc2dbhW0K4e"
      },
      "source": [
        "# Data Cleaning \n",
        "Lets take a look at some reviews to see what data cleaning measures we need \n",
        "* We can see that we need to remove punctuation and that some reviews have a lot of white space \n",
        "* Both uppercase and lowercase letters are present \n",
        "* There are numerical digits as well \n",
        "* Some reviews contain expressions such as \"this/that\" and simply removing '/' results in \"thisthat\" instead of \"this that\" \n",
        "* Some reviews contained only punctuation (e.g. '.', ': )', '*') \n",
        "* Some reviews do not have proper spacing (e.g. 'Don't misinterpret my review....I' which turns into 'dont misinterpret my reviewi')\n",
        "* There are reviews in Chinese and Spanish \n",
        "* Had some strange letters show up such as 'entr√É¬©es' due to encoding/decoding issues\n",
        "* Some reviews have website links in them "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNCN4mmV0KRi",
        "outputId": "a0255304-f2a1-4030-b7f0-2726510e6d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review 1:\n",
            " Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House‚Ä¶ https://t.co/n3tggDLU1L\n",
            "Review 2:\n",
            " RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia‚Ä¶\n",
            "Review 3:\n",
            " RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages. \n",
            "\n",
            "Congress has allocated about $18‚Ä¶\n",
            "Review 4:\n",
            " RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.‚Ä¶\n",
            "Review 5:\n",
            " RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico‚Äôs readiness...well ü§¶üèº‚Äç‚ôÇÔ∏èüò°üò©@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY\n",
            "Review 1:\n",
            " Check out my op-ed on need for End Executive Overreach Act: The White House is crippling our economy https://t.co/XCmjLB8Qyd via @DCExaminer\n",
            "Review 2:\n",
            " Yesterday, Betty &amp; I had a great time learning about the forestry industry which employs approx 44,000 people in GA. https://t.co/364HhW6wp3\n",
            "Review 3:\n",
            " We are forever grateful for the service and sacrifice of Major Barney. https://t.co/EeL3nxKRSt\n",
            "Review 4:\n",
            " Happy first day of school @CobbSchools! #CobbBackToSchool\n",
            "Review 5:\n",
            " #Zika fears realized in Florida. House GOP acted to prevent crisis. Dems inaction, inexcusable! Time to put politics aside &amp; work together!\n"
          ]
        }
      ],
      "source": [
        "for index,text in enumerate(tweets['Tweet'][:5]):\n",
        "  print('Review %d:\\n'%(index+1),text)\n",
        "for index,text in enumerate(tweets['Tweet'][-5:]):\n",
        "  print('Review %d:\\n'%(index+1),text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets['cleaned'] = tweets['Tweet'].copy().str.normalize('NFKD')\\\n",
        "       .str.encode('ascii', errors='ignore')\\\n",
        "       .str.decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pandas Apply: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85729/85729 [06:48<00:00, 209.77it/s]\n"
          ]
        }
      ],
      "source": [
        "tweets['language'] = tweets['Tweet'].swifter.apply(detect_language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepEspaillat</td>\n",
              "      <td>ICYMI- @RepEspaillat @NydiaVelazquez @RepJeffr...</td>\n",
              "      <td>icymi join nycha residents local leaders prote...</td>\n",
              "      <td>icymi join nycha resident local leader protest...</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepEspaillat</td>\n",
              "      <td>RT @THEKIDMERO: METE MANO TIO!! üá©üá¥üí™üèΩ https://t...</td>\n",
              "      <td>thekidmero mete mano tio</td>\n",
              "      <td>thekidmero mete mano tio</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepBRochester</td>\n",
              "      <td>üëáüèæ#GetCovered https://t.co/nwj5i9185l</td>\n",
              "      <td>getcovered</td>\n",
              "      <td>getcovere</td>\n",
              "      <td>da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepTomSuozzi</td>\n",
              "      <td>@randimarshall @Amtrak Thank you!</td>\n",
              "      <td>randimarshall amtrak thank you</td>\n",
              "      <td>randimarshall amtrak thank</td>\n",
              "      <td>id</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1541</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepRoKhanna</td>\n",
              "      <td>Thanks for having me! https://t.co/QiOzWvboqZ</td>\n",
              "      <td>thanks for having me</td>\n",
              "      <td>thank have</td>\n",
              "      <td>da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85621</th>\n",
              "      <td>Republican</td>\n",
              "      <td>RobWittman</td>\n",
              "      <td>Stay safe today, folks. https://t.co/FPeYJBCho...</td>\n",
              "      <td>stay safe today folks</td>\n",
              "      <td>stay safe today folk</td>\n",
              "      <td>so</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85853</th>\n",
              "      <td>Republican</td>\n",
              "      <td>RosLehtinen</td>\n",
              "      <td>Thx @WeAreALPA! Safer skies benefit us all! ht...</td>\n",
              "      <td>thx wearealpa safer skies benefit us all</td>\n",
              "      <td>thx wearealpa safe sky benefit</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85902</th>\n",
              "      <td>Republican</td>\n",
              "      <td>WaysandMeansGOP</td>\n",
              "      <td>RT @PeterRoskam: https://t.co/ETliUWGvJc</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86069</th>\n",
              "      <td>Republican</td>\n",
              "      <td>GOPpolicy</td>\n",
              "      <td>We will #NeverForget. https://t.co/097kB5vI5Q</td>\n",
              "      <td>we will neverforget</td>\n",
              "      <td>neverforget</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86312</th>\n",
              "      <td>Republican</td>\n",
              "      <td>RepTomPrice</td>\n",
              "      <td>#Obamacare just doesn‚Äôt make sense! Our #Bette...</td>\n",
              "      <td>obamacare just doesnt make sense our betterway...</td>\n",
              "      <td>obamacare not sense betterway plan give contro...</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>612 rows √ó 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Party           Handle  \\\n",
              "657      Democrat     RepEspaillat   \n",
              "798      Democrat     RepEspaillat   \n",
              "935      Democrat    RepBRochester   \n",
              "1204     Democrat     RepTomSuozzi   \n",
              "1541     Democrat      RepRoKhanna   \n",
              "...           ...              ...   \n",
              "85621  Republican       RobWittman   \n",
              "85853  Republican      RosLehtinen   \n",
              "85902  Republican  WaysandMeansGOP   \n",
              "86069  Republican        GOPpolicy   \n",
              "86312  Republican      RepTomPrice   \n",
              "\n",
              "                                                   Tweet  \\\n",
              "657    ICYMI- @RepEspaillat @NydiaVelazquez @RepJeffr...   \n",
              "798    RT @THEKIDMERO: METE MANO TIO!! üá©üá¥üí™üèΩ https://t...   \n",
              "935                üëáüèæ#GetCovered https://t.co/nwj5i9185l   \n",
              "1204                   @randimarshall @Amtrak Thank you!   \n",
              "1541       Thanks for having me! https://t.co/QiOzWvboqZ   \n",
              "...                                                  ...   \n",
              "85621  Stay safe today, folks. https://t.co/FPeYJBCho...   \n",
              "85853  Thx @WeAreALPA! Safer skies benefit us all! ht...   \n",
              "85902           RT @PeterRoskam: https://t.co/ETliUWGvJc   \n",
              "86069      We will #NeverForget. https://t.co/097kB5vI5Q   \n",
              "86312  #Obamacare just doesn‚Äôt make sense! Our #Bette...   \n",
              "\n",
              "                                                 cleaned  \\\n",
              "657    icymi join nycha residents local leaders prote...   \n",
              "798                             thekidmero mete mano tio   \n",
              "935                                           getcovered   \n",
              "1204                      randimarshall amtrak thank you   \n",
              "1541                                thanks for having me   \n",
              "...                                                  ...   \n",
              "85621                              stay safe today folks   \n",
              "85853           thx wearealpa safer skies benefit us all   \n",
              "85902                                                      \n",
              "86069                                we will neverforget   \n",
              "86312  obamacare just doesnt make sense our betterway...   \n",
              "\n",
              "                                              lemmatized language  \n",
              "657    icymi join nycha resident local leader protest...       fr  \n",
              "798                             thekidmero mete mano tio       pt  \n",
              "935                                            getcovere       da  \n",
              "1204                          randimarshall amtrak thank       id  \n",
              "1541                                          thank have       da  \n",
              "...                                                  ...      ...  \n",
              "85621                               stay safe today folk       so  \n",
              "85853                     thx wearealpa safe sky benefit       de  \n",
              "85902                                                          sv  \n",
              "86069                                        neverforget       nl  \n",
              "86312  obamacare not sense betterway plan give contro...       fr  \n",
              "\n",
              "[612 rows x 6 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.loc[tweets['language'] != 'en']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets = tweets[tweets['language'] == 'en']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shafz\\anaconda3\\envs\\practice\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "tweets.drop('language', axis = 1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "vCO-4CBnAWlg"
      },
      "outputs": [],
      "source": [
        "## Expanding Contractions \n",
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                     \"you've\": \"you have\"}\n",
        "\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "rWvyJ5_dAg0s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-59-285874caca0b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned'] = tweets['Tweet'].apply(lambda x:expand_contractions(x))\n"
          ]
        }
      ],
      "source": [
        "# expanding contractions \n",
        "tweets['cleaned'] = tweets['Tweet'].apply(lambda x:expand_contractions(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3C9Y0Zcp0_70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-60-18eedc3572b4>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', ' ', x))\n",
            "<ipython-input-60-18eedc3572b4>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].str.lower().apply(lambda x: re.sub(r\"[\\d\\n\\-\\./]+\", ' ', x))\n",
            "<ipython-input-60-18eedc3572b4>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n",
            "<ipython-input-60-18eedc3572b4>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n"
          ]
        }
      ],
      "source": [
        "## Making all words lowercase, removing punctuation, URLs, and white spaces \n",
        "tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', ' ', x))\n",
        "tweets['cleaned']  = tweets['cleaned'].str.lower().apply(lambda x: re.sub(r\"[\\d\\n\\-\\./]+\", ' ', x))\n",
        "tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n",
        "tweets['cleaned']  = tweets['cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-4f685818c205>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].replace(' ', np.nan)\n",
            "<ipython-input-61-4f685818c205>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned']  = tweets['cleaned'].replace('', np.nan)\n"
          ]
        }
      ],
      "source": [
        "tweets['cleaned']  = tweets['cleaned'].replace(' ', np.nan)\n",
        "tweets['cleaned']  = tweets['cleaned'].replace('', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-62-deaee447563b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned'] = tweets['cleaned'].apply(lambda x: x.replace('rt ', '').strip())\n"
          ]
        }
      ],
      "source": [
        "# apply the lambda function to the 'text' column using the apply() method\n",
        "tweets['cleaned'] = tweets['cleaned'].apply(lambda x: x.replace('rt ', '').strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pandas Apply: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85117/85117 [00:04<00:00, 20650.37it/s]\n",
            "<ipython-input-63-0f81beaa65c6>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned'] = tweets['cleaned'].swifter.apply(lambda x: replace_word(x, words_to_check))\n"
          ]
        }
      ],
      "source": [
        "def replace_word(text, words_to_check):\n",
        "    for word in words_to_check:\n",
        "        if word in text: \n",
        "            text = text.replace(word, '')\n",
        "    return text\n",
        "\n",
        "\n",
        "words_to_check = list(pd.Series(tweets['Handle'].unique()).str.lower())\n",
        "# apply the function to the 'text' column\n",
        "tweets['cleaned'] = tweets['cleaned'].swifter.apply(lambda x: replace_word(x, words_to_check))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Party         0\n",
              "Handle        0\n",
              "Tweet         0\n",
              "cleaned       0\n",
              "lemmatized    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Party, Handle, Tweet, cleaned, lemmatized]\n",
              "Index: []"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.loc[tweets['cleaned'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shafz\\anaconda3\\envs\\practice\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "tweets.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-67-071da767706f>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tweets['cleaned'] = tweets['cleaned'].apply(lambda x: re.sub(' +',' ',x))\n"
          ]
        }
      ],
      "source": [
        "tweets['cleaned'] = tweets['cleaned'].apply(lambda x: re.sub(' +',' ',x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKBX9oY8ClA9",
        "outputId": "5a8d9334-51cd-41c4-89a8-b75422af1d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review 1:\n",
            " today senate dems vote to savetheinternet proud to supposimilar netneutrality legislation here in the house\n",
            "Review 2:\n",
            " winterhavensun winter haven resident alta vista teacher is one of several recognized by for national teacher apprecia\n",
            "Review 3:\n",
            " nbclatino noted that hurricane maria has left approximately billion in damages congress has allocated about\n",
            "Review 4:\n",
            " nalcabpolicy meeting with thanks for taking the time to meet with latinoleader ed marucci guzman nalcabpolicy\n",
            "Review 5:\n",
            " vegalteno hurricane season starts on june st puerto ricos readiness well pwr puertorico espaillatny\n",
            "Review 1:\n",
            " check out my op ed on need for end executive overreach act the white house is crippling our economy via dcexaminer\n",
            "Review 2:\n",
            " yesterday betty amp i had a great time learning about the forestry industry which employs approx people in ga\n",
            "Review 3:\n",
            " we are forever grateful for the service and sacrifice of major barney\n",
            "Review 4:\n",
            " happy first day of school cobbschools cobbbacktoschool\n",
            "Review 5:\n",
            " zika fears realized in florida house gop acted to prevent crisis dems inaction inexcusable time to put politics aside amp work together\n"
          ]
        }
      ],
      "source": [
        "for index,text in enumerate(tweets['cleaned'][:5]):\n",
        "  print('Review %d:\\n'%(index+1),text)\n",
        "for index,text in enumerate(tweets['cleaned'][-5:]):\n",
        "  print('Review %d:\\n'%(index+1),text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
              "      <td>today senate dems vote to savetheinternet prou...</td>\n",
              "      <td>today senate dem vote savetheinternet proud su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
              "      <td>winterhavensun winter haven resident alta vist...</td>\n",
              "      <td>winterhavensun winter haven resident alta vist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
              "      <td>nbclatino noted that hurricane maria has left ...</td>\n",
              "      <td>nbclatino note hurricane maria leave approxima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
              "      <td>nalcabpolicy meeting with thanks for taking th...</td>\n",
              "      <td>nalcabpolicy meeting thank take time meet lati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
              "      <td>vegalteno hurricane season starts on june st p...</td>\n",
              "      <td>vegalteno hurricane season start june st puert...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Party         Handle                                              Tweet  \\\n",
              "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
              "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
              "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
              "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
              "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
              "\n",
              "                                             cleaned  \\\n",
              "0  today senate dems vote to savetheinternet prou...   \n",
              "1  winterhavensun winter haven resident alta vist...   \n",
              "2  nbclatino noted that hurricane maria has left ...   \n",
              "3  nalcabpolicy meeting with thanks for taking th...   \n",
              "4  vegalteno hurricane season starts on june st p...   \n",
              "\n",
              "                                          lemmatized  \n",
              "0  today senate dem vote savetheinternet proud su...  \n",
              "1  winterhavensun winter haven resident alta vist...  \n",
              "2  nbclatino note hurricane maria leave approxima...  \n",
              "3  nalcabpolicy meeting thank take time meet lati...  \n",
              "4  vegalteno hurricane season start june st puert...  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "n3I9KaOZhs1C"
      },
      "outputs": [],
      "source": [
        "tweets.to_csv('./tweets_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slo6BGrvDRR2"
      },
      "source": [
        "Removing stop words, lemmatizing, and tokenizing \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yR0f7ABSDVbV"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xel_-rrHhQg",
        "outputId": "861bf6c7-809f-4b78-dad1-76710a5fd1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'one', \"n't\", 'his', 'because', 'often', 'part', 'yours', 'we', 'moreover', 'for', 'every', 'front', 'been', 'she', 'twelve', 'not', 'of', 'since', 'your', 'whenever', 'sixty', 'see', 'he', 'few', 'therefore', 'my', 'why', 'make', 'seems', 'nor', 'doing', 'might', 'into', 'alone', 'some', 'me', 'whither', 'off', 'take', 'or', 'could', 'will', 'whereafter', 'was', 'although', 'their', 'him', 'have', 'wherein', 'own', 'last', 'always', 'anyway', 'than', 'is', 'up', 'toward', 'her', 'more', 'be', 'put', 'may', 'another', 'fifty', 'whom', 'which', 'whose', 'back', 'did', 'say', 'whether', 'everything', 'throughout', 'when', 'such', 'somehow', 'himself', 'does', 'nevertheless', 'something', 'by', '‚Äôve', 'too', 'seemed', '‚Äôs', 'bottom', 'cannot', 'themselves', 'upon', 'no', 'here', \"'m\", 'would', 'myself', 'rather', 'them', 'down', 'behind', 'formerly', 'anywhere', 'those', 'former', 'less', 'various', 'out', 'nine', 'thus', 'empty', 'thereby', 'nothing', 're', 'the', 'an', 'two', \"'ve\", 'during', 'however', 'indeed', 'but', 'only', '‚Äòll', 'should', 'twenty', '‚Äòre', 'can', 'thereupon', 'us', '‚Äôre', 'first', 'all', 'who', 'its', 'anyhow', 'ourselves', 'never', 'same', 'without', 'while', 'sometimes', 'noone', 'whereas', 'around', 'so', '‚Äôm', 'forty', 'other', 'itself', 'everyone', 'whole', 'amount', 'someone', 'latter', 'get', 'really', 'it', 'used', 'anyone', 'already', 'several', 'in', 'unless', 'except', 'somewhere', 'ten', 'just', \"'re\", 'though', 'whoever', 'also', 'six', 'hereafter', 'still', 'even', 'has', 'then', 'full', 'wherever', \"'s\", 'ca', 'there', '‚Äòve', 'whatever', 'and', 'on', 'that', 'keep', 'hers', 'became', 'further', 'whereby', 'hence', 'ours', '‚Äôll', 'nobody', 'go', 'next', 'name', 'hundred', 'else', 'well', 'therein', 'three', 'very', \"'d\", 'they', 'to', 'hereupon', 'am', 'what', 'move', 'third', 'were', 'against', 'onto', 'between', 'n‚Äôt', 'top', 'four', 'towards', 'over', 'side', 'eight', 'perhaps', 'namely', 'many', 'together', 'i', 'these', 'fifteen', 'quite', 'meanwhile', 'either', 'regarding', 'within', 'using', 'whence', 'this', 'give', 'any', 'neither', 'afterwards', 'ever', 'thereafter', 'are', 'if', '‚Äòd', 'until', 'as', '‚Äôd', 'below', 'none', 'herself', 'five', 'with', 'where', 'besides', 'elsewhere', 'nowhere', 'again', 'now', 'amongst', 'before', 'yet', 'both', 'call', 'beside', 'herein', 'how', 'do', 'eleven', 'among', 'along', 'each', 'seem', 'become', 'otherwise', 'almost', 'from', 'our', 'through', 'enough', 'thru', 'anything', 'mine', 'much', 'once', 'made', 'latterly', '‚Äòs', 'becomes', '‚Äòm', 'hereby', 'seeming', 'done', 'had', 'whereupon', 'above', 'under', 'everywhere', 'beforehand', 'show', 'about', 'please', 'via', 'n‚Äòt', 'across', 'yourselves', 'becoming', 'others', 'a', 'most', 'being', 'must', 'yourself', 'due', 'mostly', 'serious', 'sometime', \"'ll\", 'least', 'thence', 'you', 'at', 'beyond', 'per', 'after'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(nlp.Defaults.stop_words)\n",
        "len(nlp.Defaults.stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "325"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.Defaults.stop_words -= {'not'}\n",
        "len(nlp.Defaults.stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "aw1DvjyWeNLs"
      },
      "outputs": [],
      "source": [
        "texts = tweets['cleaned'].tolist()\n",
        "lemmatized_texts = []\n",
        "for doc in nlp.pipe(texts, batch_size=1000, n_process=4):\n",
        "    lemmatized_texts.append(' '.join([token.lemma_ for token in doc if (token.is_stop==False)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets['lemmatized'] = lemmatized_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Party         0\n",
              "Handle        0\n",
              "Tweet         0\n",
              "cleaned       0\n",
              "lemmatized    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Party, Handle, Tweet, cleaned, lemmatized]\n",
              "Index: []"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.loc[tweets['lemmatized'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
              "      <td>today senate dems vote to savetheinternet prou...</td>\n",
              "      <td>today senate dem vote savetheinternet proud su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
              "      <td>winterhavensun winter haven resident alta vist...</td>\n",
              "      <td>winterhavensun winter haven resident alta vist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
              "      <td>nbclatino noted that hurricane maria has left ...</td>\n",
              "      <td>nbclatino note hurricane maria leave approxima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
              "      <td>nalcabpolicy meeting with thanks for taking th...</td>\n",
              "      <td>nalcabpolicy meeting thank take time meet lati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
              "      <td>vegalteno hurricane season starts on june st p...</td>\n",
              "      <td>vegalteno hurricane season start june st puert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
              "      <td>emgageactionfl thank you to all who came out t...</td>\n",
              "      <td>emgageactionfl thank come orlando gala success...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
              "      <td>hurricane maria left approx billion in damages...</td>\n",
              "      <td>hurricane maria leave approx billion damage bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
              "      <td>tharryry i am delighted that will be voting fo...</td>\n",
              "      <td>tharryry delighted vote cra overrule fcc save ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
              "      <td>hispaniccaucus trump is anti immigrant policie...</td>\n",
              "      <td>hispaniccaucus trump anti immigrant policy hur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Democrat</td>\n",
              "      <td>RepDarrenSoto</td>\n",
              "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
              "      <td>great joining weareunidosus and for a roundta...</td>\n",
              "      <td>great join weareunidosus roundtable orlando ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Party         Handle                                              Tweet  \\\n",
              "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
              "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
              "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
              "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
              "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
              "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...   \n",
              "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...   \n",
              "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...   \n",
              "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...   \n",
              "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos...   \n",
              "\n",
              "                                             cleaned  \\\n",
              "0  today senate dems vote to savetheinternet prou...   \n",
              "1  winterhavensun winter haven resident alta vist...   \n",
              "2  nbclatino noted that hurricane maria has left ...   \n",
              "3  nalcabpolicy meeting with thanks for taking th...   \n",
              "4  vegalteno hurricane season starts on june st p...   \n",
              "5  emgageactionfl thank you to all who came out t...   \n",
              "6  hurricane maria left approx billion in damages...   \n",
              "7  tharryry i am delighted that will be voting fo...   \n",
              "8  hispaniccaucus trump is anti immigrant policie...   \n",
              "9   great joining weareunidosus and for a roundta...   \n",
              "\n",
              "                                          lemmatized  \n",
              "0  today senate dem vote savetheinternet proud su...  \n",
              "1  winterhavensun winter haven resident alta vist...  \n",
              "2  nbclatino note hurricane maria leave approxima...  \n",
              "3  nalcabpolicy meeting thank take time meet lati...  \n",
              "4  vegalteno hurricane season start june st puert...  \n",
              "5  emgageactionfl thank come orlando gala success...  \n",
              "6  hurricane maria leave approx billion damage bi...  \n",
              "7  tharryry delighted vote cra overrule fcc save ...  \n",
              "8  hispaniccaucus trump anti immigrant policy hur...  \n",
              "9    great join weareunidosus roundtable orlando ...  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets.to_csv('./lemmatized_tweets.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
