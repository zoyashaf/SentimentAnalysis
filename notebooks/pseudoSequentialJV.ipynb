{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IEAkGAmXFH0T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.utils import resample\n",
        "(x_train, y_train), (x_test, y_test)= imdb.load_data(num_words =10000)\n",
        "x_unlabeled = resample(x_train, n_samples=15000, replace=False, stratify=x_train, random_state=0)\n",
        "\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_words = 10000\n",
        "num_classes = max(y_train) + 1\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "x_unlabeled_ = tokenizer.sequences_to_matrix(x_unlabeled, mode='binary')\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(x_train[0])\n",
        "print(len(x_train[0]))\n",
        "\n",
        "print(y_train[0])\n",
        "print(len(y_train[0]))\n",
        "\n",
        "\n",
        "#for embedding purposes makes sure all samples are of the same length\n",
        "from keras import preprocessing\n",
        "maxlen = 1000 #max 100 words per input\n",
        "x_train_ =tf.keras.utils.pad_sequences(x_train, maxlen = maxlen)\n",
        "x_test_ = tf.keras.utils.pad_sequences(x_test, maxlen = maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4HznybKFSIU",
        "outputId": "8932a991-7f9b-40c7-f9f5-86029ed46caf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "[0. 1. 1. ... 0. 0. 0.]\n",
            "10000\n",
            "[0. 1.]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.alpha_w = 0.0\n",
        "    self.n_classes=2\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch < 10:\n",
        "        self.alpha_w = 0.0\n",
        "    elif epoch >= 70:\n",
        "        self.alpha_w = 3.0\n",
        "    else:\n",
        "        self.alpha_w = (epoch - 10.0) / (70.0-10.0) * 3.0\n",
        "    \n",
        "    #coefs =(1+ self.alpha_w)\n",
        "    #logs[\"loss\"] = logs[\"loss\"]*coefs\n",
        "\n",
        "  def loss_function(self, y, y_pred):\n",
        "\n",
        "    #y_batch, np.repeat(0.0, y_batch.shape[0])\n",
        "    #cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    #y = np.c_[y, np.repeat(0.0, y.shape[0])]\n",
        "    #y_true_item = y[:, :self.n_classes]\n",
        "    #unlabeled_flag = y[:, self.n_classes]\n",
        "    \"\"\"\n",
        "    from_logits: Whether to interpret `y_pred` as a tensor of\n",
        "            [logit](https://en.wikipedia.org/wiki/Logit) values. By default, we\n",
        "            assume that `y_pred` contains probabilities (i.e., values in [0,\n",
        "            1]).\n",
        "    \"\"\"\n",
        "    entropies = categorical_crossentropy(y, y_pred)\n",
        "    coefs = 1 + self.alpha_w\n",
        "    self.loss = coefs * entropies\n",
        "    #1.0-unlabeled_flag + self.alpha_w * unlabeled_flag # 1 if labeled, else alpha_t\n",
        "    return coefs * entropies\n",
        "\n",
        "  def accuracy(self, y, y_pred):\n",
        "\n",
        "    y_true_item = y[:, :self.n_classes]\n",
        "    return categorical_accuracy(y_true_item, y_pred)\n",
        "  "
      ],
      "metadata": {
        "id": "d3IcaLJHFe96"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "filepath = \"/content/gdrive/MyDrive/den_yelp_notebooks/weights.hdf5\""
      ],
      "metadata": {
        "id": "yy1EFCvDFh2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keras_model():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(maxlen, 5))\n",
        "  model.add(tf.keras.layers.LSTM(5))\n",
        "\n",
        "  model.add(Dense(512, input_shape=(maxlen,), activation = \"relu\"))\n",
        "  #dropping with prob. 0.5\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation = \"softmax\"))\n",
        "  # CustomCallback\n",
        "  #model.compile(\"adam\", loss=pseudo.loss_function, metrics=[pseudo.accuracy])\n",
        "  #model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"acc\"] )\n",
        "  #model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "QP9l63KZFkgE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "call_back = CustomCallback()\n",
        "model = keras_model()\n",
        "model.compile(\"adam\", loss=call_back.loss_function, metrics=[call_back.accuracy])"
      ],
      "metadata": {
        "id": "bCcZhSKFFpt6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  #for every odd i fir with labeled data\n",
        "  if i%2 == 0:\n",
        "    model.fit(x_train_, y_train, epochs = 100, verbose =2, batch_size = 700)\n",
        "  else:\n",
        "    x_unlabeled_sam = resample(x_unlabeled_, n_samples=1000, replace=False, stratify=x_unlabeled, random_state=0)\n",
        "    pseudo_labels = model.predict(x_unlabeled_sam)\n",
        "    pseudo_labels_ =np.argmax(pseudo_labels, axis=-1,).reshape(-1, 1)\n",
        "    pseudo_labels_ = tf.keras.utils.to_categorical(pseudo_labels_, num_classes)\n",
        "    history = model.fit(x_unlabeled_sam, pseudo_labels_, epochs = 30, verbose =2, \\\n",
        "                        callbacks=[call_back], batch_size = 500, \\\n",
        "                        validation_data=(x_test_[:700], y_test[:700]) )\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dgQemtm4Ftan",
        "outputId": "53811385-1021-4785-9248-254d11c6cff0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 - 31s - loss: 0.6934 - accuracy: 0.4924 - 31s/epoch - 854ms/step\n",
            "Epoch 2/100\n",
            "36/36 - 29s - loss: 0.6932 - accuracy: 0.4959 - 29s/epoch - 797ms/step\n",
            "Epoch 3/100\n",
            "36/36 - 28s - loss: 0.6932 - accuracy: 0.4988 - 28s/epoch - 777ms/step\n",
            "Epoch 4/100\n",
            "36/36 - 29s - loss: 0.6932 - accuracy: 0.5011 - 29s/epoch - 795ms/step\n",
            "Epoch 5/100\n",
            "36/36 - 28s - loss: 0.6932 - accuracy: 0.5006 - 28s/epoch - 769ms/step\n",
            "Epoch 6/100\n",
            "36/36 - 28s - loss: 0.6933 - accuracy: 0.4977 - 28s/epoch - 781ms/step\n",
            "Epoch 7/100\n",
            "36/36 - 27s - loss: 0.6931 - accuracy: 0.5050 - 27s/epoch - 753ms/step\n",
            "Epoch 8/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.4964 - 27s/epoch - 743ms/step\n",
            "Epoch 9/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.4978 - 27s/epoch - 758ms/step\n",
            "Epoch 10/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.4957 - 27s/epoch - 764ms/step\n",
            "Epoch 11/100\n",
            "36/36 - 28s - loss: 0.6932 - accuracy: 0.4956 - 28s/epoch - 778ms/step\n",
            "Epoch 12/100\n",
            "36/36 - 28s - loss: 0.6932 - accuracy: 0.4975 - 28s/epoch - 775ms/step\n",
            "Epoch 13/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.4976 - 27s/epoch - 754ms/step\n",
            "Epoch 14/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.4999 - 27s/epoch - 760ms/step\n",
            "Epoch 15/100\n",
            "36/36 - 28s - loss: 0.6931 - accuracy: 0.5010 - 28s/epoch - 780ms/step\n",
            "Epoch 16/100\n",
            "36/36 - 29s - loss: 0.6931 - accuracy: 0.5042 - 29s/epoch - 807ms/step\n",
            "Epoch 17/100\n",
            "36/36 - 30s - loss: 0.6933 - accuracy: 0.4954 - 30s/epoch - 847ms/step\n",
            "Epoch 18/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.5009 - 27s/epoch - 761ms/step\n",
            "Epoch 19/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.5004 - 27s/epoch - 756ms/step\n",
            "Epoch 20/100\n",
            "36/36 - 27s - loss: 0.6932 - accuracy: 0.5008 - 27s/epoch - 761ms/step\n",
            "Epoch 21/100\n",
            "36/36 - 28s - loss: 0.6932 - accuracy: 0.4952 - 28s/epoch - 775ms/step\n",
            "Epoch 22/100\n",
            "36/36 - 28s - loss: 0.6931 - accuracy: 0.5014 - 28s/epoch - 778ms/step\n",
            "Epoch 23/100\n",
            "36/36 - 28s - loss: 0.6931 - accuracy: 0.5021 - 28s/epoch - 790ms/step\n",
            "Epoch 24/100\n",
            "36/36 - 27s - loss: 0.6931 - accuracy: 0.5027 - 27s/epoch - 753ms/step\n",
            "Epoch 25/100\n",
            "36/36 - 27s - loss: 0.6931 - accuracy: 0.5003 - 27s/epoch - 761ms/step\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cb42614143ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#for every odd i fir with labeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_unlabeled_sam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_unlabeled_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_d = history.history\n",
        "loss_values = h_d['loss']\n",
        "val_loss_values = h_d[\"val_loss\"]\n",
        "epochs = range(1, len(h_d['accuracy'])+1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label = \"Training Loss\")\n",
        "plt.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n",
        "plt.title(\"Training and Validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ExpvBZ7DHad3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}